# Practicum AI: Deep Learning Foundations


![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_500x100.png?raw=true) <img src='https://github.com/PracticumAI/deep_learning/blob/main/images/deep_learning_foundations.png?raw=true' align='right' width=100>

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PracticumAI/deep_learning)

## Module 1: Neural Network Basics Objectives

By the end of this module, you will be able to:

1.	Define a neural network. 
2.	Describe how a neural network works. 
3.	Discuss deep networks.
4.	Discuss what can be done with neural networks.
5.	Use a deep learning pre-trained model to classify an image. 
6.	Discuss Python AI Frameworks.

### Module 1 Notebooks

* [01_deep_learning_tour.ipynb](01_deep_learning_tour.ipynb)

## Module 2: Neural Network Advanced Objectives

By the end of this module, you will be able to:

1.	Describe the basis of a neural network (neuron).
2.	Identify and describe an artificial neuron (perceptron).
3.	Discuss bias and weights.
4.	Describe and identify activation functions.
5.	Describe and simulate image processing in a small neural network.
6.	Implement and train a perceptron using TensorFlow.

### Module 2 Notebooks

* [02_code_a_perceptron.ipynb](02_code_a_perceptron.ipynb)
* [03_mnist_classifier.ipynb](03_mnist_classifier.ipynb)

## Module 3 Optimization Algorithms and Hyperparameter Tuning Objectives

By the end of this module, you will be able to:
1.	Describe the purpose and process of gradient descent.
2.	Discuss the error loss function.
3.	Describe optimizers.
4.	Experiment with hyperparameter tuning.

### Module 3 Notebooks

* [04_bees_vs_wasps.ipynb](04_bees_vs_wasps.ipynb)

***
#### Videos
[DL : Neural Networks - Getting Started](https://mediasite.video.ufl.edu/Mediasite/Play/31f4838bc2d84b97b46b46eadb0748621d)

[DL : Anatomy of a Neural Network](https://mediasite.video.ufl.edu/Mediasite/Play/372d802f29744e15b21f2c4273f45f831d)

#### Links
[Lawrence Moroney Video](https://www.youtube.com/watch?v=VwVg9jCtqaU)

#### Notes
1. Vanishing / exploding gradients problem (*Hands-On Machine Learning w/Sci-Kit Learn...*, p. 332 - ff)
2. Backpropagation Summary (*Learning Deep Learning, Eckman*, p. 89.)
3. Learning Rate Hyperparameter (*Deep Learning: A Visual Approach, Glassner*, p. 376.) -- Excellent example!

